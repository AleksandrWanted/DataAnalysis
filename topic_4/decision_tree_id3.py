# Задание
# Возьмите за основу какой-нибудь пример (не менее 4-5 значений выходной переменной Y,
# не менее 7-8 признаков, входных переменных (x1,x2,x3,…), влияющих на решение).
# Опишите, что означают выбранные классы и признаки.
# Следя за экспертом, запишите решения Y эксперта в нескольких случаях и значения известной при этом информации (x1,x2,x3,…),
# не менее 20 строк в таблице экспериментов (то есть принятых решений).
# Рассчитайте дерево.
# Постройте по дереву логическую функцию (уравнение, модель).
# Спрогнозируйте новую строку таблицы, неизвестную эксперту ранее.
# Приведите геометрическую интерпретацию решения.


import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.tree import export_text

data = {
    'Возраст': [2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2],
    'Состояние': [3, 4, 1, 2, 3, 4, 2, 1, 2, 4, 2, 1, 2, 3, 1, 2, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1],
    'Пробег': [1, 2, 3, 1, 2, 3, 2, 3, 1, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 1],
    'Количество владельцев': [2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3],
    'Наличие ДТП': [2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],
    'Ликвидность': [1, 2, 3, 1, 2, 3, 2, 3, 1, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 1],
    'Цена продажи': [2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3],
    'Срок реализации': [1, 1, 4, 1, 2, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, 1, 1, 2, 4, 1, 2, 3, 2]
}

df = pd.DataFrame(data)

# Определение признаков и целевой переменной
x = df.drop(columns='Срок реализации')  # Признаки
y = df['Срок реализации']  # Целевая переменная

# Создание и обучение модели дерева решений
clf = DecisionTreeClassifier(criterion='entropy')  # Используем энтропию для ID3
clf.fit(x, y)

# Визуализация дерева решений
plt.figure(figsize=(12, 8))
tree.plot_tree(clf,
               feature_names=x.columns,
               class_names=[str(i) for i in clf.classes_],
               filled=True)
plt.show()

# Получение правил дерева
rules = export_text(clf,
                    feature_names=list(x.columns))
print(rules)

# Создание новой строки (экземпляра) данных
new_data = pd.DataFrame({
    'Возраст': [3],
    'Состояние': [2],
    'Пробег': [2],
    'Количество владельцев': [1],
    'Наличие ДТП': [1],
    'Ликвидность': [2],
    'Цена продажи': [3]
})

# Прогнозирование
prediction = clf.predict(new_data)
print(f"Прогнозируемый срок реализации: {prediction[0]}")

# Выбор двух признаков для визуализации
X_vis = df[['Возраст', 'Состояние']]
y_vis = df['Срок реализации']

# Обучение модели только на двух признаках
clf_vis = DecisionTreeClassifier(criterion='entropy')
clf_vis.fit(X_vis.values, y_vis.values)

# Создание сетки для визуализации границ принятия решений
x_min, x_max = X_vis['Возраст'].min() - 1, X_vis['Возраст'].max() + 1
y_min, y_max = X_vis['Состояние'].min() - 1, X_vis['Состояние'].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                     np.arange(y_min, y_max, 0.01))

# Прогнозирование по сетке
Z = clf_vis.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)


# Визуализация
plt.contourf(xx, yy, Z, alpha=0.3)
plt.scatter(X_vis['Возраст'], X_vis['Состояние'], c=y_vis, edgecolor='k', s=20)
plt.scatter(new_data['Возраст'], new_data['Состояние'], color='red', s=100, label='Новая строка')
plt.xlabel('Возраст')
plt.ylabel('Состояние')
plt.title('Границы принятия решений дерева решений')
# plt.legend()
plt.show()
